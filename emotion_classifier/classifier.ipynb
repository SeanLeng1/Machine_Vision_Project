{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a21e41b",
   "metadata": {},
   "source": [
    "<h1>CSC 249 Model Training</h1>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac98ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import cv2\n",
    "import os\n",
    "import glob \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import tensorflow as tf\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import transforms, models\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "from numba import cuda\n",
    "from PIL import Image\n",
    "from copy import copy\n",
    "import splitfolders\n",
    "from torchsummary import summary\n",
    "# import scheduler for learning rate change\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import collections\n",
    "#import tensorflowjs\n",
    "\n",
    "# resampling reference: https://github.com/ufoym/imbalanced-dataset-sampler\n",
    "from torchsampler import ImbalancedDatasetSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c574a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you might not need this if your testing set has been divided into publictest and privatetest\n",
    "def split():\n",
    "    import os, os.path, shutil\n",
    "\n",
    "    folder_path = \"C:/Users/jixua/OneDrive/Desktop/Machine learning package/archive/test/surprise\"\n",
    "    old_path = \"C:/Users/jixua/OneDrive/Desktop/Machine learning package/test_data_2/public\"\n",
    "    new_path = \"C:/Users/jixua/OneDrive/Desktop/Machine learning package/test_data_2/private\"\n",
    "    #images = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "    images = os.listdir(folder_path)\n",
    "    print(images)\n",
    "\n",
    "    for image in images:\n",
    "        folder_name = image.split('_')[0]\n",
    "        #new_path = os.path.join(folder_path, folder_name)\n",
    "        if not os.path.exists(new_path):\n",
    "            os.makedirs(new_path)\n",
    "\n",
    "        old_image_path = os.path.join(old_path, image)\n",
    "        new_image_path = os.path.join(new_path, image)\n",
    "        shutil.move(old_image_path, new_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add194a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the image is grayscale or colored\n",
    "import cv2\n",
    "file = \"C:/Users/jixua/OneDrive/Desktop/Machine learning package/archive/train/angry/Training_3908.jpg\"\n",
    "\n",
    "image = cv2.imread(file)\n",
    "if image.any() != None:\n",
    "    if(len(image.shape)<2):\n",
    "        print ('grayscale')\n",
    "    elif len(image.shape)==3:\n",
    "        print ('Colored')\n",
    "else:\n",
    "    print(\"cannot find image\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f080d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding gaussian noise transforms\n",
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0.0, std=1.0):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a698c4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing the data, creating dataset and dataloader\n",
    "# load in data directory\n",
    "data_dir = 'C:/Users/jixua/OneDrive/Desktop/Machine learning package'\n",
    "classes = os.listdir(data_dir + \"/archive/train\")\n",
    "#print(classes)\n",
    "\n",
    "# split the training set into training set and validation set (0.9 : 0.1)\n",
    "# splitfolders.ratio(data_dir + '/archive/train', output = 'data', seed = 1337, ratio = (0.9, 0.1, 0))\n",
    "\n",
    "# normalize according to pytorch pretrained model\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "#mu, st = 0, 255\n",
    "    \n",
    "# resnet50 is for 224\n",
    "# data augmentation and normalization for trainning data\n",
    "train_image_transform = transforms.Compose([\n",
    "    #transforms.Resize([256,256]),\n",
    "    #transforms.RandomResizedCrop(224),\n",
    "    #transforms.RandomAffine(degrees = 0, translate = (0.1, 0.1)),\n",
    "    #transforms.RandomVerticalFlip(),\n",
    "    #transforms.GaussianBlur(kernel_size = 3),\n",
    "    #transforms.RandomRotation(10),\n",
    "    #transforms.RandomAffine(degrees = 180, translate = (0.1, 0.1)),\n",
    "    #transforms.RandomHorizontalFlip(),\n",
    "    #transforms.Grayscale(num_output_channels=3),\n",
    "    #transforms.ToTensor(),\n",
    "    #normalize,\n",
    "    transforms.Grayscale(),\n",
    "    transforms.RandomResizedCrop([48,48], scale = (0.8, 1.2)),\n",
    "    transforms.RandomApply([transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5)], p=0.5),\n",
    "    transforms.RandomApply([transforms.RandomAffine(0, translate=(0.1, 0.1))], p=0.5),\n",
    "    transforms.RandomApply([transforms.RandomRotation(10)], p=0.5), \n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.FiveCrop(40),\n",
    "    transforms.Lambda(lambda crops : torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n",
    "    transforms.Lambda(lambda tensors: torch.stack([transforms.RandomErasing()(t) for t in tensors])),\n",
    "        \n",
    "    #transforms.Lambda(lambda tensors: torch.stack([normalize(t) for t in tensors])),\n",
    "    #transforms.Lambda(lambda tensors: torch.stack([transforms.RandomApply([AddGaussianNoise(0.1, 0.02)], p=0.5)(t) for t in tensors])),\n",
    "])\n",
    "\n",
    "# only data normalization for validation data and test data\n",
    "no_augmentation_transform = transforms.Compose([\n",
    "    #transforms.ten\n",
    "    transforms.Resize([224, 224]),\n",
    "    #transforms.Grayscale(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "    \n",
    "    \n",
    "no_crop_transform = transforms.Compose([\n",
    "    transforms.Resize(48),\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "    \n",
    "valid_image_transform = transforms.Compose([\n",
    "    transforms.Resize(48),\n",
    "    transforms.Grayscale(),\n",
    "    transforms.TenCrop(40),\n",
    "    transforms.Lambda(lambda crops : torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n",
    "    #transforms.Lambda(lambda tensors: torch.stack([normalize(t) for t in tensors])),\n",
    "])\n",
    "    \n",
    "test_image_transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize(48),\n",
    "    transforms.TenCrop(40),\n",
    "    transforms.Lambda(lambda crops : torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n",
    "    #transforms.Lambda(lambda tensors: torch.stack([normalize(t) for t in tensors])),\n",
    "])\n",
    "    \n",
    "    \n",
    "# train set is reading from the train folder\n",
    "train_set = torchvision.datasets.ImageFolder(data_dir + '/archive/train', transform = train_image_transform)\n",
    "\n",
    "\n",
    "# valid set should not have transformation\n",
    "valid_set = torchvision.datasets.ImageFolder(data_dir + '/test_data/public', transform = valid_image_transform)\n",
    "\n",
    "#train_set_temp, valid_set = Data.random_split(valid_data_set, [train_size, valid_size])\n",
    "    \n",
    "\n",
    "# batch_size might affect cuda memory\n",
    "#train_loader = Data.DataLoader(dataset = train_set, sampler=ImbalancedDatasetSampler(train_set), batch_size = 256, num_workers=0)\n",
    "train_loader = Data.DataLoader(dataset = train_set, batch_size = 256, shuffle = True, num_workers=0)\n",
    "valid_loader = Data.DataLoader(dataset = valid_set, batch_size = 256, shuffle = True, num_workers=0)\n",
    "\n",
    "# create testing set\n",
    "# testing set is reading from the test folder\n",
    "test_set_no_aug = torchvision.datasets.ImageFolder(data_dir + '/test_data/private', transform = no_crop_transform)\n",
    "    \n",
    "test_set = torchvision.datasets.ImageFolder(data_dir + '/test_data/private', transform = test_image_transform)\n",
    "    \n",
    "test_loader = Data.DataLoader(dataset = test_set, batch_size = 256, shuffle = True, num_workers=0)\n",
    "    \n",
    "test_loader_no_aug = Data.DataLoader(dataset = test_set_no_aug, batch_size = 128, shuffle = True, num_workers=0)\n",
    "    \n",
    "    \n",
    "# get label class\n",
    "labels_class = train_set.classes\n",
    "    \n",
    "# get number of samples in each class\n",
    "print(dict(collections.Counter(train_set.targets)))\n",
    "    \n",
    "# generate loss weight\n",
    "class_weights = torch.tensor([1/3395, 1/436, 1/4097, 1/7215, 1/4965, 1/4830, 1/3171])\n",
    "print(class_weights)\n",
    "print(labels_class)\n",
    "    \n",
    "    #return train_set, train_loader, valid_loader, test_loader, test_image_transform, valid_image_transform, \n",
    "    #labels_class, class_weights, no_augmentation_transform, test_loader_no_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e446eb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_set, train_loader, valid_loader, test_loader, test_image_transform, valid_image_transformation, labels_class, class_weights, no_augmentation_transform, test_loader_2 = preprocessing()\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd319b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize some of the training data and testing validing data\n",
    "def show_data(dataloader):\n",
    "    for data in dataloader:\n",
    "        images, labels = data\n",
    "        bs, ncrops, c, h, w = images.size()\n",
    "        images = images.view(-1, c, h, w)\n",
    "        fig, ax = plt.subplots(figsize=(12, 12))\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        ax.imshow(torchvision.utils.make_grid(images[:100], nrow=8).permute(1,2,0))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f5ec84",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print(len(train_loader))\n",
    "show_data(train_loader)\n",
    "show_data(valid_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdde112f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# output the hitogram for experimental results\n",
    "data_dir = 'C:/Users/jixua/OneDrive/Desktop/Machine learning package'\n",
    "x_dict = dict(collections.Counter(train_set.targets))\n",
    "x = []\n",
    "for key in x_dict:\n",
    "    x.append(x_dict[key])\n",
    "print(x)\n",
    "\n",
    "x = pd.Series(x)\n",
    "x_label = labels_class\n",
    "plt.figure(figsize = (5, 5))\n",
    "ax = x.plot(kind = 'bar')\n",
    "ax.set_title('Training data set distribution')\n",
    "#ax.set_xlabel('class')\n",
    "ax.set_ylabel('number')\n",
    "ax.set_xticklabels(x_label, rotation = 'horizontal')\n",
    "\n",
    "rects = ax.patches\n",
    "\n",
    "# label each accuracy\n",
    "labels = x\n",
    "for rect, label in zip(rects, labels):\n",
    "    height = rect.get_height()\n",
    "    ax.text(rect.get_x() + rect.get_width() / 10, height + 20, label)\n",
    "plt.savefig('Comparison.png', facecolor = 'w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3b02e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the model, using pytorch pretrained model, 3 choices (resnet50, vgg16, and densenet)\n",
    "def model_set_up(name):\n",
    "    device = torch.device('cuda') if torch.cuda.is_available else torch.device('cpu')\n",
    "    #print(device)\n",
    "\n",
    "    if name == 'resnet':\n",
    "        net = models.resnet50(pretrained = True)\n",
    "        num_fcs = net.fc.in_features\n",
    "        net.fc = nn.Sequential(#nn.Dropout(0.5),\n",
    "                               #nn.Flatten(),\n",
    "                            nn.Linear(num_fcs, 4096),\n",
    "                            nn.LeakyReLU(),\n",
    "                            #nn.Dropout(0.5),\n",
    "                            nn.Linear(4096, 1024),\n",
    "                            #nn.BatchNorm1d(1024),\n",
    "                            nn.LeakyReLU(),\n",
    "                            #nn.Dropout(0.5),\n",
    "                            nn.Linear(1024, 7))\n",
    "\n",
    "        net.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) \n",
    "\n",
    "    \n",
    "    if name == 'vgg':\n",
    "        net = models.vgg16_bn(pretrained = True)\n",
    "        num_fcs = net.classifier[6]. in_features\n",
    "        net.classifier[6] = nn.Linear(num_fcs, 7)\n",
    "        net.features[0] = torch.nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) \n",
    "    \n",
    "    if name == 'densenet':\n",
    "        net = models.densenet161(pretrained=True)\n",
    "        net.features[0] = torch.nn.Conv2d(1, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "        num_fcs = net.classifier.in_features\n",
    "        net.classifier = nn.Linear(num_fcs, 7)\n",
    "        \n",
    "    if name == 'wide_resnet':\n",
    "        net = models.wide_resnet50_2(pretrained = True)\n",
    "        net.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) \n",
    "        num_fcs = net.fc.in_features\n",
    "        net.fc = nn.Linear(num_fcs, 7)\n",
    "        \n",
    "    if name == 'regnet':\n",
    "        net = models.regnet_x_32gf(pretrained = True)\n",
    "        net.stem[0] = torch.nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
    "        num_fcs = net.fc.in_features\n",
    "        net.fc = nn.Linear(num_fcs, 7)\n",
    "        \n",
    "    if name == \"efficientnet\":\n",
    "        net = models.efficientnet_b7(pretrained = True)\n",
    "        net.features[0][0] = torch.nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "        num_fcs = net.classifier[1].in_features\n",
    "        net.classifier[1] = nn.Linear(num_fcs, 7)\n",
    "\n",
    "        \n",
    "    # unfreeze the base model\n",
    "    for param in net.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    # define criterion, optimizer\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001, nesterov=True)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    #criterion = nn.NLLLoss() \n",
    " \n",
    "    # move the net to gpu\n",
    "    net = net.to(device)\n",
    "    \n",
    "    print(net)\n",
    "    \n",
    "    return net, optimizer, criterion, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8a1225",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "net, optimizer, criterion, device = model_set_up('vgg')\n",
    "#sum(p.numel() for p in net.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc690c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "# get the summary of the model\n",
    "summary(net, input_size=(256, 1, 48, 48))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb592799",
   "metadata": {},
   "source": [
    "  $x = \\lambda x_{i} + (1 - \\lambda)x_{j}$\n",
    "  \n",
    "  $y = \\lambda y_{i} + (1 - \\lambda)y_{j}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92092ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_smooth(true_labels: torch.Tensor, classes: int, smoothing=0.0):\n",
    "    #if smoothing == 0, it's one-hot method\n",
    "    #if 0 < smoothing < 1, it's smooth method\n",
    "    \n",
    "    #print(f\"true: {true_labels}\")\n",
    "    device = true_labels.device\n",
    "    true_labels = torch.nn.functional.one_hot(true_labels, classes).detach().cpu()\n",
    "    assert 0 <= smoothing < 1\n",
    "    confidence = 1.0 - smoothing\n",
    "    label_shape = torch.Size((true_labels.size(0), classes))\n",
    "    with torch.no_grad():\n",
    "        true_dist = torch.empty(size=label_shape, device=true_labels.device)\n",
    "        true_dist.fill_(smoothing / (classes - 1))\n",
    "        _, index = torch.max(true_labels, 1)\n",
    "\n",
    "        true_dist.scatter_(1, torch.LongTensor(index.unsqueeze(1)), confidence)\n",
    "    #print(f\"smooth: {true_dist}\")\n",
    "    return true_dist.to(device)\n",
    "\n",
    "# mixup paper reference: https://doi.org/10.48550/arXiv.1710.09412\n",
    "def mixup_data(x, y, alpha=0.2):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "        \n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).cuda()\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae29686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(net, epochs, optimizer, criterion, name):\n",
    "    scaler = GradScaler()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    #scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=10, min_lr=0.00001, verbose=1)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = epochs)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracy = []\n",
    "    val_accuracy = []\n",
    "    best_accuracy = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        net.train()\n",
    "        running_loss_train = 0.0\n",
    "        running_loss_val = 0.0\n",
    "        val_total = 0.0\n",
    "        train_total = 0.0\n",
    "        val_correct = 0.0\n",
    "        train_correct = 0.0\n",
    "        for i, data in enumerate(train_loader):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Automatic Mixed Precision\n",
    "            with autocast():\n",
    "                # according to pytorch documentation, fivecrop creates more dimension\n",
    "                bs, ncrops, c, h, w = inputs.shape\n",
    "                inputs = inputs.view(-1, c, h, w)\n",
    "                \n",
    "                # repeat the labels tensor to fit inputs crop\n",
    "                labels = torch.repeat_interleave(labels, repeats = ncrops, dim = 0) \n",
    "\n",
    "\n",
    "                inputs, labels_a, labels_b, lam = mixup_data(inputs, labels, 0.2)\n",
    "                inputs, labels_a, labels_b = map(Variable, (inputs, labels_a, labels_b))\n",
    "\n",
    "                outputs = net(inputs)\n",
    "\n",
    "                soft_labels_a = label_smooth(labels_a, classes = 7, smoothing = 0.1)\n",
    "                soft_labels_b = label_smooth(labels_b, classes = 7, smoothing = 0.1)\n",
    "        \n",
    "                # use CrossEntropyLoss if no mix-up\n",
    "                #loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "                \n",
    "                # use mixup loss function if there is mix-up\n",
    "                loss = mixup_criterion(criterion, outputs, soft_labels_a, soft_labels_b, lam)\n",
    "                \n",
    "                # nivdia Automatic Mixed Precision\n",
    "                optimizer.zero_grad()\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "                running_loss_train += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                \n",
    "                train_total += labels.size()[0]\n",
    "                train_correct += torch.sum(preds == labels.data).item()\n",
    "            \n",
    "        train_losses.append(running_loss_train / len(train_loader.sampler))\n",
    "        train_accuracy.append(train_correct / train_total)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            for val_data in valid_loader:\n",
    "                val_inputs, val_labels = val_data\n",
    "                val_inputs = val_inputs.cuda()\n",
    "                val_labels = val_labels.cuda()\n",
    "                \n",
    "                bs, ncrops_val, c, h, w = val_inputs.shape\n",
    "                val_inputs = val_inputs.view(-1, c, h, w)\n",
    "                \n",
    "                prediction = net(val_inputs)\n",
    "                \n",
    "                # average over crops\n",
    "                prediction = prediction.view(bs, ncrops_val, -1)\n",
    "                prediction = torch.sum(prediction, dim = 1) / ncrops_val\n",
    "                \n",
    "                val_loss = criterion(prediction, val_labels)\n",
    "                \n",
    "                \n",
    "                running_loss_val += val_loss.item() * val_inputs.size(0)\n",
    "                _, predicted = torch.max(prediction, 1)\n",
    "                val_total += val_labels.size()[0]\n",
    "                val_correct += torch.sum(predicted == val_labels.data).item()\n",
    "            \n",
    "        val_losses.append(running_loss_val / len(valid_loader.sampler))\n",
    "        val_accuracy.append(val_correct / val_total)\n",
    "        \n",
    "        curr_lr = optimizer.param_groups[0]['lr']\n",
    "        scheduler.step()\n",
    "        \n",
    "        # divide loss by the number of crops to get average loss\n",
    "        print(f'Epoch {epoch + 1} \\t \\\n",
    "            Training Loss: {running_loss_train / len(train_loader.sampler)} \\t \\\n",
    "            Validation Loss: {running_loss_val / len(valid_loader.sampler)} \\t \\\n",
    "            Training Accuracy: {train_correct / train_total} \\t \\\n",
    "            Validation Accuracy: {val_correct / val_total} \\t \\\n",
    "            LR: {curr_lr}\\n' )\n",
    "        \n",
    "\n",
    "        # save the best model\n",
    "        if (val_correct / val_total) > best_accuracy:\n",
    "            torch.save(net, f'C:/Users/jixua/OneDrive/Desktop/Machine learning package/{name}')\n",
    "            best_accuracy = val_correct / val_total\n",
    "            \n",
    "    # learning curve\n",
    "    #fig, ax = plt.subplots()\n",
    "    #plt.figure(figsize = (10,4))\n",
    "    fig = plt.figure(figsize = (10,8))\n",
    "    \n",
    "    ax1 = fig.add_subplot(221)\n",
    "    ax1.plot(train_losses, 'r', label = 'train_loss')\n",
    "    ax1.plot(val_losses, 'g', label = 'val_loss')\n",
    "    ax1.legend(loc = \"upper right\")\n",
    "    ax1.set_title(\"Learning curve\")\n",
    "\n",
    "    # accuracy curve\n",
    "    ax2 = fig.add_subplot(223)\n",
    "    ax2.plot(train_accuracy, 'r', label = 'train_accuracy')\n",
    "    ax2.plot(val_accuracy, 'g', label = 'val_accuracy')\n",
    "    ax2.legend(loc = \"upper right\")\n",
    "    ax2.set_title(\"Accuracy curve\")\n",
    "    #plt.show()\n",
    "    \n",
    "    # save the model\n",
    "    #torch.save(net, 'C:/Users/jixua/OneDrive/Desktop/Machine learning package/resnet50')\n",
    "    \n",
    "    # save the plot\n",
    "    fig.savefig(f\"curve_{name}.pdf\")\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551bb53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_model(net, 150, optimizer, criterion, 'efficientnet_tmax150')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1ac1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# caclculate accuracy on test loader\n",
    "def accuracy(model, device, crop, testloader = test_loader):\n",
    "    \n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            \n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            if crop == True:\n",
    "                bs, ncrops, c, h, w = images.shape\n",
    "                images = images.view(-1, c, h, w)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            \n",
    "            if crop == True:\n",
    "                outputs = outputs.view(bs, ncrops, -1)\n",
    "                outputs = torch.sum(outputs, dim=1) / ncrops\n",
    "            \n",
    "            _, outputs = torch.max(outputs.data, 1)\n",
    "            test_total += labels.size()[0]\n",
    "            test_correct += torch.sum(outputs == labels.data).item()\n",
    "            \n",
    "    print(f'correct: {test_correct}')\n",
    "    print(f'total: {test_total}')       \n",
    "    print(f'Accuracy of the network on the {test_total} testing images: {100 * test_correct / test_total} %')\n",
    "    return (test_correct / test_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3318cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "trained_model = torch.load('resnet50_elite_test2_tmax150')\n",
    "accuracy1 = accuracy(trained_model, device, True, test_loader)\n",
    "#print(accuracy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51f2a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is only for our testing purpose\n",
    "def test(model):\n",
    "    model = model.to(device)\n",
    "    # testing on new images, maybe transform - special_case_dataloader\n",
    "    image = Image.open('C:/Users/jixua/OneDrive/Desktop/Machine learning package/archive/special_case/happy/zhuzhu_box.jpg')\n",
    "    image = image.convert(\"RGB\")\n",
    "    image_tensor = test_image_transform(image)\n",
    "    image_variable = Variable(image_tensor.unsqueeze(0))\n",
    "    image_variable = image_variable.to(device)\n",
    "    bs, ncrops, c, h, w = image_variable.shape\n",
    "    #print(image_variable.shape)\n",
    "    image_variable = image_variable.view(-1, c, h, w)\n",
    "    #print(image_variable.shape)\n",
    "\n",
    "    outputs = model(image_variable)\n",
    "    outputs = outputs.view(bs, ncrops, -1)\n",
    "    outputs = torch.sum(outputs, dim=1) / ncrops\n",
    "    \n",
    "    # because the last layer is linear \n",
    "    h_x = torch.nn.functional.softmax(outputs, dim = 1).data.squeeze()\n",
    "    probs, idx = h_x.sort(0, True)\n",
    "    #print(idx[0])\n",
    "    \n",
    "    display(image)\n",
    "    print('predicted classes: {}. probability:{:.3f}'.format(labels_class[idx[0].item()], probs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1a8658",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(torch.load(\"ensemble_model6_tmax150\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32cca68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize some results\n",
    "def visualize(model, num_images = 10):\n",
    "    model = model.to(device)\n",
    "    # inverse transform\n",
    "    images_number = 0\n",
    "    #inverse_transform = test_image_transform\n",
    "    fig = plt.figure()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            bs, ncrops, c, h, w = images.shape\n",
    "            images = images.view(-1, c, h, w)\n",
    "            \n",
    "            prediction = model(images)\n",
    "            \n",
    "            #prediction = prediction.view(bs, ncrops, -1)\n",
    "            #prediction = torch.sum(prediction, dim=1) / ncrops\n",
    "            # uncomment this if using softmax activation\n",
    "            #prediction = torch.exp(prediction)\n",
    "            \n",
    "            prediction = torch.nn.functional.softmax(prediction,dim = 1)\n",
    "            _, predicted = torch.max(prediction, 1)\n",
    "            prediction_label = torch.max(prediction).item()\n",
    "            #prediction_label = round(prediction_label, 5)\n",
    "            \n",
    "            for i in range(images.size(0)):\n",
    "                images_number += 1\n",
    "                ax = plt.subplot(5, 2, images_number)\n",
    "                ax.axis('off')\n",
    "                #ax.set_title(f'prediced: {labels_class[predicted[i]]} {prediction_label * 100}%')\n",
    "                ax.set_title(f'predicted: {labels_class[predicted[i]]}')\n",
    "                #print(images.cpu().data[i])\n",
    "                plt.imshow(images.cpu().data[i].permute(1,2,0))\n",
    "                #plt.imshow(images_inverse.numpy())              \n",
    "                # 0<= images_number <=  num_images, break when it's out range\n",
    "                if images_number == num_images:\n",
    "                    return\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ad6e90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = torch.load('ensemble_model5_2_tmax150')\n",
    "visualize(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4747f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# does not work on tencrop\n",
    "# reference: https://medium.com/intelligentmachines/implementation-of-class-activation-map-cam-with-pytorch-c32f7e414923\n",
    "features_blobs = []\n",
    "def hook_feature(module, input, output):\n",
    "    features_blobs.append(output.data.cpu().numpy())\n",
    "\n",
    "def CAM(features_conv, weight_softmax, class_idx):\n",
    "    size_unsample = (256, 256)\n",
    "    bz, nc, h, w = features_conv.shape\n",
    "    output_cam = []\n",
    "    for _ in class_idx:\n",
    "        cam = weight_softmax[class_idx].dot(features_conv.reshape((nc, h*w)))\n",
    "        cam = cam.reshape(h, w)\n",
    "        cam = cam - np.min(cam)\n",
    "        cam_img = cam / np.max(cam)\n",
    "        \n",
    "        cam_img = np.uint8(255 * cam_img)\n",
    "        output_cam.append(cv2.resize(cam_img, size_unsample))\n",
    "    return output_cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466344c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference: https://notebook.community/\n",
    "def draw_CAM(model, path, index, valid_transform):\n",
    "    finalconv_name = 'layer4' # subject to change(depend on the network architecture)\n",
    "    model = model.to('cpu') # you can change to gpu if you have memory left \n",
    "    model.eval()\n",
    "    \n",
    "    model._modules.get(finalconv_name).register_forward_hook(hook_feature)\n",
    "    \n",
    "    # get the softmax weight\n",
    "    params = list(model.parameters())\n",
    "    weight_softmax = np.squeeze(params[-2].data.cpu().numpy())\n",
    "    \n",
    "    # process the image and run through the network, return the highest probability and label_class index\n",
    "    image = Image.open(path)\n",
    "    image = image.convert(\"RGB\")\n",
    "    image_tensor = valid_transform(image)\n",
    "    image_variable = Variable(image_tensor.unsqueeze(0))\n",
    "    \n",
    "    #bs, ncrops, c, h, w = image_variable.shape\n",
    "    #image_variable = image_variable.view(-1, c, h, w)\n",
    "    \n",
    "    image_variable = image_variable.to('cpu')\n",
    "\n",
    "    \n",
    "    logit = model(image_variable)\n",
    "    \n",
    "    #logit = logit.view(bs, ncrops, -1)\n",
    "    #logit = torch.sum(logit, dim=1) / ncrops\n",
    "    \n",
    "    h_x = torch.nn.functional.softmax(logit, dim = 1).data.squeeze()\n",
    "    probs, idx = h_x.sort(0, True)\n",
    "    \n",
    "    # only formatting here does the correct rounding\n",
    "    print('predicted classes: {}. probability:{:.3f}'.format(labels_class[idx[0].item()], probs[0])) \n",
    "    \n",
    "    img = cv2.imread(path)\n",
    "    height, width, _ = img.shape\n",
    "    CAMs = CAM(features_blobs[0], weight_softmax, [idx[0].item()])\n",
    "\n",
    "    heatmap = cv2.applyColorMap(cv2.resize(CAMs[0], (width, height)), cv2.COLORMAP_JET)\n",
    "    result = heatmap * 0.4 + img * 0.5\n",
    "    cv2.imwrite(f'CAM/CAM{index}.jpg', result)\n",
    "    \n",
    "    plt.imshow(Image.open(f'CAM/CAM{index}.jpg'))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd6044c",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_CAM(torch.load('resnet50'), 'C:/Users/jixua/OneDrive/Desktop/Machine learning package/test_data/private/happy/PrivateTest_2028370.jpg', 5, no_augmentation_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54449da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mode\n",
    "# caclculate accuracy on test loader\n",
    "def max_voting(model1, model2, model3, model4, device, crop):\n",
    "    \n",
    "    model1 = model1.to(device)\n",
    "    model1.eval()\n",
    "    model2 = model2.to(device)\n",
    "    model2.eval()\n",
    "    model3 = model3.to(device)\n",
    "    model3.eval()\n",
    "    model4 = model4.to(device)\n",
    "    model4.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            \n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            if crop == True:\n",
    "                bs, ncrops, c, h, w = images.shape\n",
    "                images = images.view(-1, c, h, w)\n",
    "            \n",
    "            outputs1 = model1(images)\n",
    "            outputs2 = model2(images)\n",
    "            outputs3 = model3(images)\n",
    "            outputs4 = model4(images)\n",
    "            if crop == True:\n",
    "                outputs1 = outputs1.view(bs, ncrops, -1)\n",
    "                outputs1 = torch.sum(outputs1, dim=1) / ncrops\n",
    "                outputs2 = outputs2.view(bs, ncrops, -1)\n",
    "                outputs2 = torch.sum(outputs2, dim=1) / ncrops\n",
    "                outputs3 = outputs3.view(bs, ncrops, -1)\n",
    "                outputs3 = torch.sum(outputs3, dim=1) / ncrops\n",
    "                outputs4 = outputs4.view(bs, ncrops, -1)\n",
    "                outputs4 = torch.sum(outputs4, dim=1) / ncrops\n",
    "            \n",
    "            _, outputs1 = torch.max(outputs1.data, 1)\n",
    "            _, outputs2 = torch.max(outputs2.data, 1)\n",
    "            _, outputs3 = torch.max(outputs3.data, 1)\n",
    "            _, outputs4 = torch.max(outputs4.data, 1)\n",
    "            \n",
    "            final_output = [outputs1, outputs2, outputs3, outputs4]\n",
    "            final_output = mode(final_output) \n",
    "            #final_output = (outputs1 + outputs2 + outputs3)/3\n",
    "            test_total += labels.size()[0]\n",
    "            test_correct += torch.sum(final_output == labels.data).item()\n",
    "    print(f'correct: {test_correct}')\n",
    "    print(f'total: {test_total}')       \n",
    "    print(f'Accuracy of the network on the {test_total} testing images: {100 * test_correct / test_total} %')\n",
    "    return (test_correct / test_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46648236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nvidia autocast scaler does not work when require_grad is false\n",
    "def train_model_no_autocast(net, epochs, name):\n",
    "    device = 'cuda'\n",
    "    # define criterion, optimizer\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001, nesterov=True)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    #scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=10, min_lr=0.00001, verbose=1)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = epochs)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracy = []\n",
    "    val_accuracy = []\n",
    "    best_accuracy = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        net.train()\n",
    "        running_loss_train = 0.0\n",
    "        running_loss_val = 0.0\n",
    "        val_total = 0.0\n",
    "        train_total = 0.0\n",
    "        val_correct = 0.0\n",
    "        train_correct = 0.0\n",
    "        for i, data in enumerate(train_loader):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Automatic Mixed Precision\n",
    "            # according to pytorch documentation, fivecrop creates more dimension\n",
    "            bs, ncrops, c, h, w = inputs.shape\n",
    "            inputs = inputs.view(-1, c, h, w)\n",
    "                \n",
    "            # repeat the labels tensor to fit inputs crop\n",
    "            labels = torch.repeat_interleave(labels, repeats = ncrops, dim = 0) \n",
    "\n",
    "\n",
    "            inputs, labels_a, labels_b, lam = mixup_data(inputs, labels, 0.2)\n",
    "            inputs, labels_a, labels_b = map(Variable, (inputs, labels_a, labels_b))\n",
    "\n",
    "\n",
    "            outputs = net(inputs)  \n",
    "\n",
    "            soft_labels_a = label_smooth(labels_a, classes = 7, smoothing = 0.1)\n",
    "            soft_labels_b = label_smooth(labels_b, classes = 7, smoothing = 0.1)\n",
    "        \n",
    "            # use CrossEntropyLoss if no mix-up\n",
    "            #loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "                \n",
    "            # use mixup loss function if there is mix-up\n",
    "            loss = mixup_criterion(criterion, outputs, soft_labels_a, soft_labels_b, lam)\n",
    "                \n",
    "            # nivdia Automatic Mixed Precision\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss_train += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "                \n",
    "            train_total += labels.size()[0]\n",
    "            train_correct += torch.sum(preds == labels.data).item()\n",
    "            \n",
    "        train_losses.append(running_loss_train / len(train_loader.sampler) /5)\n",
    "        train_accuracy.append(train_correct / train_total)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            for val_data in valid_loader:\n",
    "                val_inputs, val_labels = val_data\n",
    "                val_inputs = val_inputs.cuda()\n",
    "                val_labels = val_labels.cuda()\n",
    "                \n",
    "                bs, ncrops_val, c, h, w = val_inputs.shape\n",
    "                val_inputs = val_inputs.view(-1, c, h, w)\n",
    "                \n",
    "                prediction = net(val_inputs)\n",
    "                \n",
    "                # average over crops\n",
    "                prediction = prediction.view(bs, ncrops_val, -1)\n",
    "                prediction = torch.sum(prediction, dim = 1) / ncrops_val\n",
    "                \n",
    "                val_loss = criterion(prediction, val_labels)\n",
    "                \n",
    "                \n",
    "                running_loss_val += val_loss.item() * val_inputs.size(0)\n",
    "                _, predicted = torch.max(prediction, 1)\n",
    "                val_total += val_labels.size()[0]\n",
    "                val_correct += torch.sum(predicted == val_labels.data).item()\n",
    "            \n",
    "        val_losses.append(running_loss_val / len(valid_loader.sampler) /10)\n",
    "        val_accuracy.append(val_correct / val_total)\n",
    "        \n",
    "        curr_lr = optimizer.param_groups[0]['lr']\n",
    "        scheduler.step()\n",
    "        \n",
    "        # divide loss by the number of crops to get average loss\n",
    "        print(f'Epoch {epoch + 1} \\t \\\n",
    "            Training Loss: {running_loss_train / len(train_loader.sampler) / 5} \\t \\\n",
    "            Validation Loss: {running_loss_val / len(valid_loader.sampler) /10} \\t \\\n",
    "            Training Accuracy: {train_correct / train_total} \\t \\\n",
    "            Validation Accuracy: {val_correct / val_total} \\t \\\n",
    "            LR: {curr_lr}\\n' )\n",
    "        \n",
    "\n",
    "        # save the best model\n",
    "        if (val_correct / val_total) > best_accuracy:\n",
    "            torch.save(net, f'C:/Users/jixua/OneDrive/Desktop/Machine learning package/{name}')\n",
    "            best_accuracy = val_correct / val_total\n",
    "            \n",
    "    # learning curve\n",
    "    #fig, ax = plt.subplots()\n",
    "    #plt.figure(figsize = (10,4))\n",
    "    fig = plt.figure(figsize = (10,8))\n",
    "    \n",
    "    ax1 = fig.add_subplot(221)\n",
    "    ax1.plot(train_losses, 'r', label = 'train_loss')\n",
    "    ax1.plot(val_losses, 'g', label = 'val_loss')\n",
    "    ax1.legend(loc = \"upper right\")\n",
    "    ax1.set_title(\"Learning curve\")\n",
    "\n",
    "    # accuracy curve\n",
    "    ax2 = fig.add_subplot(223)\n",
    "    ax2.plot(train_accuracy, 'r', label = 'train_accuracy')\n",
    "    ax2.plot(val_accuracy, 'g', label = 'val_accuracy')\n",
    "    ax2.legend(loc = \"upper right\")\n",
    "    ax2.set_title(\"Accuracy curve\")\n",
    "    #plt.show()\n",
    "    \n",
    "    # save the model\n",
    "    #torch.save(net, 'C:/Users/jixua/OneDrive/Desktop/Machine learning package/resnet50')\n",
    "    \n",
    "    # save the plot\n",
    "    fig.savefig(f\"curve_{name}.pdf\")\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15871cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = torch.load('resnet50_elite_test2_tmax150')\n",
    "model2 = torch.load('vgg16_elite_test_tmax150')\n",
    "model3 = torch.load('densenet_elite_test_tmax150')\n",
    "model4 = torch.load('wide_resnet')\n",
    "model5 = torch.load('regnet_tmax150')\n",
    "model6 = torch.load('efficientnet_tmax150')\n",
    "#accuracy = max_voting(model1, model2, model3, device, True)\n",
    "#accuracy = max_voting(model1, model2, model3, model4, device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0616db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyEnsemble(nn.Module):\n",
    "    def __init__(self, model1, model2, model3, model4, num_classes=7):\n",
    "        super(MyEnsemble, self).__init__()\n",
    "        self.model1 = model1\n",
    "        self.model2 = model2\n",
    "        self.model3 = model3\n",
    "        self.model4 = model4\n",
    "        self.model5 = model5\n",
    "        self.model6 = model6\n",
    "        # Remove last linear layer\n",
    "        self.model1.fc = nn.Identity()\n",
    "        self.model2.fc = nn.Identity()\n",
    "        self.model3.fc = nn.Identity()\n",
    "        self.model4.fc = nn.Identity()\n",
    "        self.model5.fc = nn.Identity()\n",
    "        self.model6.fc = nn.Identity()\n",
    "        # Create new classifier\n",
    "        #self.classifier = nn.Linear(4110, num_classes)\n",
    "        self.classifier = nn.Sequential(#nn.Dropout(0.5),\n",
    "                               #nn.Flatten(),\n",
    "                            nn.Linear(6637, 4096),\n",
    "                            nn.LeakyReLU(),\n",
    "                            #nn.Dropout(0.5),\n",
    "                            nn.Linear(4096, 1024),\n",
    "                            #nn.BatchNorm1d(1024),\n",
    "                            nn.LeakyReLU(),\n",
    "                            #nn.Dropout(0.5),\n",
    "                            nn.Linear(1024, 7))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.model1(x.clone())  # clone to make sure x is not changed by inplace methods\n",
    "        x1 = x1.view(x1.size(0), -1)\n",
    "        x2 = self.model2(x)\n",
    "        x2 = x2.view(x2.size(0), -1)\n",
    "        x3 = self.model3(x)\n",
    "        x3 = x3.view(x3.size(0), -1)\n",
    "        x4 = self.model4(x)\n",
    "        x4 = x4.view(x4.size(0), -1)\n",
    "        x5 = self.model5(x)\n",
    "        x5 = x5.view(x5.size(0), -1)\n",
    "        x6 = self.model6(x)\n",
    "        x6 = x6.view(x6.size(0), -1)\n",
    "        \n",
    "        x = torch.cat((x1, x2, x3, x4, x5, x6), dim=1)\n",
    "        x = self.classifier(F.relu(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db92e215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze these models\n",
    "for param in model1.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for param in model2.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for param in model3.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for param in model4.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for param in model5.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for param in model6.parameters():\n",
    "    param.requires_grad = False\n",
    "# Create ensemble model\n",
    "model = MyEnsemble(model1, model2, model3, model4, model5, model6)\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "model = train_model_no_autocast(model, 50, 'ensemble_model6_tmax150')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db61cbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = torch.load('ensemble_model3_tmax150')\n",
    "#accuracy_ensemble = accuracy(model, device, True)\n",
    "#accuracy(torch.load(\"resnet50_elite_test7\"), device, False, test_loader_no_aug)\n",
    "accuracy_resnet50_all = accuracy(torch.load(\"ensemble_model6_tmax150\"), device, True)\n",
    "accuracy_test = accuracy(torch.load(\"resnet50_elite_test2_tmax150\"), device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b636b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output the hitogram for different models comparison\n",
    "# x is a list\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "accuracy_resnet50_all = accuracy(torch.load(\"resnet50_elite_test2_tmax150\"), device, True)\n",
    "#accuracy_resnet50_no_smoothing = accuracy(torch.load(\"resnet50_elite_test4\"), device, True)\n",
    "accuracy_resnet50_crop = accuracy(torch.load(\"resnet50_elite_test5\"), device, True)\n",
    "accuracy_resnet50_no_mixup_smoothing = accuracy(torch.load(\"resnet50_elite_test6\"), device, True)\n",
    "accuracy_resnet50_no_augmentation_cosine = accuracy(torch.load(\"resnet50_elite_test7\"), device, False, test_loader_no_aug)\n",
    "accuracy_resnet50_no_augmentation_reduce = accuracy(torch.load(\"resnet50_elite_test8\"), device, False, test_loader_no_aug)\n",
    "accuracy_resnet50_class_weight = accuracy(torch.load(\"resnet_elite_INS\"), device, True)\n",
    "accuracy_vgg16 = accuracy(torch.load(\"vgg16_elite_test_tmax150\"), device, True)\n",
    "accuracy_densenet = accuracy(torch.load(\"densenet_elite_test_tmax150\"), device, True)\n",
    "accuracy_wide_resnet = accuracy(torch.load(\"wide_resnet\"), device, True)\n",
    "accuracy_ensemble = accuracy(torch.load(\"ensemble_model3_tmax150\"), device, True)\n",
    "# accuracy_ensemble_model3 = accuracy(torch.load(\"ensemble_model2\", device, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace5c8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyEnsemble_3(nn.Module):\n",
    "    def __init__(self, model1, model2, model3, model4, num_classes=7):\n",
    "        super(MyEnsemble, self).__init__()\n",
    "        self.model1 = model1\n",
    "        self.model2 = model2\n",
    "        self.model3 = model3\n",
    "\n",
    "        # Remove last linear layer\n",
    "        self.model1.fc = nn.Identity()\n",
    "        self.model2.fc = nn.Identity()\n",
    "        self.model3.fc = nn.Identity()\n",
    "\n",
    "        # Create new classifier\n",
    "        self.classifier = nn.Linear(2062, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.model1(x.clone())  # clone to make sure x is not changed by inplace methods\n",
    "        x1 = x1.view(x1.size(0), -1)\n",
    "        x2 = self.model2(x)\n",
    "        x2 = x2.view(x2.size(0), -1)\n",
    "        x3 = self.model3(x)\n",
    "        x3 = x3.view(x3.size(0), -1)\n",
    "        #x5 = self.model5(x)\n",
    "        #x5 = x5.view(x5.size(0), -1)\n",
    "        \n",
    "        x = torch.cat((x1, x2, x3), dim=1)\n",
    "        x = self.classifier(F.relu(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ff342f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we decided to use excel instead :)\n",
    "accuracy_dist_1 = [accuracy_resnet50_no_augmentation_reduce, accuracy_resnet50_no_augmentation_cosine, \n",
    "                accuracy_resnet50_no_mixup_smoothing, accuracy_resnet50_crop, accuracy_resnet50_all, \n",
    "                accuracy_resnet50_class_weight, accuracy_vgg16, accuracy_densenet, accuracy_wide_resnet, \n",
    "                accuracy_ensemble]\n",
    "accuracy_dist = pd.Series(accuracy_dist_1)\n",
    "\n",
    "x_label = [\"resnet50 reduce LR\", \"resnet50 cosine annealing\", \"+ augmentation\", \"+ N-Crop\", \"+ mixup and smoothing\", \" + loss weight\",\"vgg16\", \"densenet161\", \"wide_resnet50\", \"ensemble model\"]\n",
    "\n",
    "plt.figure(figsize = (7, 7))\n",
    "ax = accuracy_dist.plot(kind = 'line')\n",
    "ax.set_title('Final models Comparison')\n",
    "#ax.set_xlabel('class')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_xticks(accuracy_dist)\n",
    "ax.set_xticklabels(x_label, rotation = 30, horizontalalignment='right')\n",
    "\n",
    "rects = ax.patches\n",
    "\n",
    "# label each accuracy\n",
    "#labels = accuracy_dist\n",
    "#for rect, label in zip(rects, labels):\n",
    "    #height = rect.get_height()\n",
    "    #ax.text(rect.get_x() + rect.get_width() / 6, height+0.01, round(label,3))\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig('Comparison_result.png', facecolor = 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2c7027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "model = torch.load(\"ensemble_model6_tmax150\")\n",
    "classes = labels_class\n",
    "len_class = len(classes)\n",
    "confusion_matrix = np.zeros((len_class, len_class))\n",
    "\n",
    "# iterate over all test data\n",
    "for data in test_loader:\n",
    "            \n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "        \n",
    "            bs, ncrops, c, h, w = images.shape\n",
    "            images = images.view(-1, c, h, w)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            \n",
    "           \n",
    "            outputs = outputs.view(bs, ncrops, -1)\n",
    "            outputs = torch.sum(outputs, dim=1) / ncrops\n",
    "            _, outputs = torch.max(outputs.data, 1)\n",
    "            for t, p in zip(labels.view(-1), outputs.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc31216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the confusion matrix\n",
    "df_cm = pd.DataFrame(confusion_matrix, index = [i for i in classes], columns = [i for i in classes])\n",
    "plt.figure(figsize = (15,10))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")\n",
    "plt.savefig('confusion_matrix.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e7b435",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
